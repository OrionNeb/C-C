---
lang: de  # Dokumentensprache: Deutsch

format:
  pdf:
    documentclass: book
    classoption: openany, oneside  # Kapitel auf jeder Seite starten (verhindert leere Seiten)
    mainfont: "Latin Modern Roman"
    fontsize: 11pt
    linestretch: 1.5  # Zeilenabstand auf 1,5 setzen (für bessere Lesbarkeit)
    code-fold: false  # Code-Chunks bleiben immer sichtbar (nicht einklappbar)
    toc: false
    toc-depth: 4
    number-sections: true
    unnumbered-sections: true
    geometry: "top=3cm, bottom=3cm, headheight=15pt, headsep=1.5cm, footskip=1.5cm"
    pdf-engine: lualatex
    listings: false
    highlight-style: tango  # Syntax-Highlighting für Code
    code-block-font-size: \tiny
    code-overflow: wrap
    include-in-header: 
      - setup/header.qmd
      - setup/glossar-eintraege.qmd
    include-before-body:
      - setup/titlepage.qmd
      - setup/gendererklaerung.qmd
      - setup/abstract.qmd
      - setup/verzeichnisse.qmd
      - setup/mainmatter.qmd
    include-after-body:
      - setup/glossar.qmd
      - setup/ehenwoertlicheErklaerung.qmd
  html:
    code-fold: true  # Code-Chunks in HTML können ausgeklappt werden
    toc: false
    toc-depth: 4
    number-sections: true
    self-contained: true  # Alle Ressourcen (Bilder, CSS, etc.) in einer Datei speichern
    other-formats: ["pdf", "docx", "pptx"]
  docx:
    toc: false
    number-sections: true
  pptx:
    reference-doc: setup/FHDW-Powerpoint-Vorlage_16zu9.pptx  # (Optional) Eigene Vorlage nutzen
bibliography: setup/references.yaml
citeproc: true
csl: https://www.zotero.org/styles/apa-with-abstract # setup/apa-with-abstract.csl
link-citations: true
link-bibliography: true
editor: source
execute:
  freeze: auto
  eval: true
  echo: true       # Code anzeigen
  results: markup  # Output als formatierten Text ausgeben
  warning: false   # Warnungen unterdrücken
  message: false   # Nachrichten (z. B. von Paketen) unterdrücken
  code-overflow: wrap  # Lange Zeilen umbrechen
---

```{r eval=TRUE, message=FALSE, warning=FALSE, include=FALSE}
# Installiere und lade erforderliche Bibliotheken
if (!requireNamespace("reticulate", quietly = TRUE)) install.packages("reticulate")
if (!requireNamespace("rmarkdown", quietly = TRUE)) install.packages("rmarkdown")
if (!requireNamespace("shiny", quietly = TRUE)) install.packages("shiny")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("tidyr", quietly = TRUE)) install.packages("tidyr")
if (!requireNamespace("tidyverse", quietly = TRUE)) install.packages("tidyverse")
if (!requireNamespace("forecast", quietly = TRUE)) install.packages("forecast")
if (!requireNamespace("ggpubr", quietly = TRUE)) install.packages("ggpubr")
# if (!requireNamespace("viridis", quietly = TRUE)) install.packages("viridis")



library(reticulate)
library(rmarkdown)
library(shiny)
library(dplyr)
library(tidyr)
library(tidyverse)
library(forecast)
library(ggpubr)
# library(viridis)
```

```{python, include=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
# Erforderliche Bibliotheken installieren (falls nicht vorhanden)
import subprocess
import sys

def install_and_import(package):
    try:
        __import__(package)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
    finally:
        globals()[package] = __import__(package)

# Äquivalente Bibliotheken in Python installieren und importieren
libraries = ["pandas", "numpy", "matplotlib", "seaborn", "scipy"]

for lib in libraries:
    install_and_import(lib)

# Bibliotheken laden
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from statsmodels.tsa.seasonal import STL
from pulp import LpMaximize, LpProblem, LpVariable, value

```



<!-- ================= 1. Einleitung ================= -->

# Einleitung {#sec-einleitung}

Laut einer Untersuchung von Mustermann [@TestEintrag1] ist das Problem bekannt.

Andere Autoren sind anderer Meinung [@TestEintrag2].

Was eine \gls{mfa} ist, wird im Glossar beschrieben.



## Problemstellung {#sec-problemstellung}

Viele Unternehmen segmentieren Kunden ausschließlich innerhalb einer einzelnen Datenquelle, etwa nur im Shop-Clickstream oder nur in Bestelldaten. Dadurch entstehen Cluster, die schwer übertragbar sind und deren Aussagekraft stark von der jeweiligen Datenwelt abhängt. Gleichzeitig verlangt das CRM nach stabilen, interpretierbaren Segmenten, die sowohl Nutzungsverhalten als auch Kaufmuster abbilden und ohne personenbezogene Daten auskommen. Es fehlt eine kompakte, belastbare Vorgehensweise, die zwei Datensätze zusammenführt, zwei unterschiedliche Clusterverfahren systematisch vergleicht und die Qualität der resultierenden Segmente mit über die Vorlesung hinausgehenden Maßen belegt.

## Zielsetzung {#sec-zielsetzung}

Diese Arbeit verfolgt drei Ziele. Erstens werden RetailRocket und Online Retail II in ein gemeinsames Ereignisschema überführt und mit datenquellenübergreifenden Merkmalen beschrieben RFM, Konversionsraten, Zeitmuster, Diversität, Zwischenkaufintervalle sowie Text-Mining über Kategoriepfade. Zweitens werden Kundencluster mit zwei kontrastierenden Verfahren gebildet K-Means und HDBSCAN und systematisch miteinander verglichen. Drittens wird die Clusterqualität umfassend bewertet mit Silhouette und Davies–Bouldin, zusätzlich DBCV für HDBSCAN, sowie die Stabilität über Bootstrapping und den Adjusted-Rand-Index; die Clustertendenz wird mit der Hopkins-Statistik geprüft. Eine Ablationsanalyse quantifiziert den Beitrag der Merkmalsgruppen.

## Vorgehensweise {#sec-vorgehensweise}

Die Studie orientiert sich strikt an CRISP-DM. Im Datenverständnis werden Struktur und Eigenschaften beider Datensätze erfasst sowie Datenschutz und Zweckbindung erläutert. In der Datenaufbereitung werden beide Quellen auf ein einheitliches Schema mit customer_id, ts, event_type, product_id, category_path, qty, revenue, channel abgebildet und ein datenquellenübergreifendes Feature-Set konstruiert. In der Modellierung werden K-Means mit Auswahl der Clusterzahl über Silhouette und Davies–Bouldin sowie HDBSCAN mit Parameterwahl über den DBCV-Index angewendet. Die Stabilität wird über wiederholte Stichproben Bootstrapping mit dem Adjusted-Rand-Index gemessen; die Clustertendenz wird mit der Hopkins-Statistik geprüft. Die Evaluation vergleicht die Verfahren je Datensatz und diskutiert Clusterprofile anhand von Kennzahlen und dominanten Kategorien. Reproduzierbarkeit wird durch eine klar strukturierte Notebook-Pipeline, feste Seeds, dokumentierte Hyperparameter und exportierte Metriktabellen sichergestellt; personenbezogene Daten werden nicht verwendet.

<!-- ================= 2. Theoretische Grundlagen ================= -->

# Grundlagen {#sec-grundlagen}

## Kundensegmentierung im CRM Kontext {#sec-kundensegmentierung}

## Datenquellen und Datenschutz RetailRocket und Online Retail II {#sec-datenquellen}

## Clusterverfahren im Überblick K-Means und HDBSCAN {#sec-clusterverfahren}

## Qualitätsmaße Silhouette Davies Bouldin DBCV Adjusted Rand Index Hopkins Calinski Harabasz {#sec-qualitaetsmasse}



<!-- ================= 3. Praxisteil ================= -->

# Praxisteil

## Datenverständnis RetailRocket Ereignisschema und Eigenschaften {#sec-datenverstaendnisRR}

## Datenverständnis Online Retail II Transaktionsschema und Eigenschaften {#sec-datenverstaendnisOR}

## Vereinheitlichung beider Datensätze gemeinsames Ereignisschema {#sec-datenvereinheitlichung}

## Datenaufbereitung und Feature Engineering RFM Konversionsproxys Zeitmuster Diversität Interkaufintervalle {#sec-datenaufbereitung}

## Text Mining auf Kategoriepfaden TF IDF optional Item2Vec {#sec-textmining}

## Clustering Ansatz 1 K-Means Auswahl der Clusterzahl über Silhouette und Davies Bouldin {#sec-clustering1}

## Clustering Ansatz 2 HDBSCAN Parameterwahl und DBCV {#sec-clustering2}

## Stabilität und Robustheit Bootstrapping und Adjusted Rand Index {#sec-stabilitaet}

## Segmentprofiling KPI Profile und Top Kategorien je Cluster {#sec-segmentprofiling}

## Reproduzierbarkeit Notebook Struktur Hyperparameter Versionierung {#sec-reproduzierbarkeit}

<!-- ================= 4. Evaluation und Ergebnisse ================= -->

# Evaluation und Ergebnisse

## Clusterqualität je Datensatz RetailRocket und Online Retail II {#sec-clusterqualitaet}

## Vergleich der Lösungen K-Means gegenüber HDBSCAN {#sec-vergleich}

## Sensitivitätsanalyse Feature Varianten und Hyperparameter {#sec-sensitivitaetsanalyse}

## Grenzen Datenqualität Sparsity Cold Start {#sec-grenzen}

<!-- ================= 5. Fazit und Ausblick ================= -->

# Fazit und Ausblick

## Beantwortung der Forschungsfrage
## Nutzen für CRM, Kampagnensteuerung und nächste Schritte
## Ausblick weitere Text Mining Merkmale und Uplift Experimente

<!-- ===
# Anhang

## A1 Prompts und Antworten der KI Hilfsmittel
## A2 Datenschemata RetailRocket und Online Retail II
## A3 Zusätzliche Tabellen zu Qualitätsmaßen und Bootstraps
## A4 Codeauszüge und Umgebungsparameter
## A5 Zusätzliche Grafiken
=== -->

<!-- ================= Literaturverzeichnis ================= -->

# Literaturverzeichnis {.unnumbered}

::: {#refs}
:::
\pagestyle{literature}
\markboth{Literaturverzeichnis}{Literaturverzeichnis}

\clearpage

<!-- ================= Anhangsverzeichnis-Header ================= -->

::: {#sec-anhang}
# Anhang {.unnumbered}
:::
\markboth{Anhang}{Anhang} 
\thispagestyle{empty}
\renewcommand{\thefigure}{A.\arabic{figure}}
\setcounter{figure}{0}



::: {#sec-anhangsverzeichnis}
## Anhangsverzeichnis {.unnumbered}
:::
\pagestyle{appendixTOC}
\noindent
<!-- ================= Anhangsverzeichnis ================= -->


**A** [Zero-Trust-Modell](#sec-anhangA) \dotfill  \pageref{sec-anhangA}

&nbsp;&nbsp;&nbsp;**A.1** [Zero-Trust-Säulen](#sec-anhangA1) \dotfill  \pageref{sec-anhangA1}

**B** [Erste Analyse der Daten](#sec-anhangB) \dotfill  \pageref{sec-anhangB}

&nbsp;&nbsp;&nbsp;**B.1** [Ergebnisse der ersten Analyse](#sec-anhangB1) \dotfill  \pageref{sec-anhangB1}
 





\clearpage

<!-- ================= Anhang ================= -->
\pagestyle{appendix} 
::: {#sec-anhangA}
# A: Zero-Trust-Modell {.unnumbered}
:::
\markboth{Anhang A: Zero-Trust-Modell}{}

::: {#sec-anhangA1}
## A1: Zero-Trust-Säulen {.unnumbered}
:::

\lorem

\clearpage

::: {#sec-anhangB}
# B: Erste Analyse der Daten {.unnumbered}
:::
\markboth{Anhang B: Erste Analyse der Daten}{}

\lorem


::: {#sec-anhangB1}
## B1: Lorem {.unnumbered}
:::

\lorem









<!-- ================= Ende ================= -->


